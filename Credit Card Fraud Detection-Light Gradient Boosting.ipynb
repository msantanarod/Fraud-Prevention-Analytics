{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11abdb4",
   "metadata": {},
   "source": [
    "#  Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1afab95",
   "metadata": {},
   "source": [
    "![fraude](fraude.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76fe549",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Welcome\" data-toc-modified-id=\"Welcome-0\">Welcome</a></span></li><li><span><a href=\"#What-does-it-mean-fraud?\" data-toc-modified-id=\"What-does-it-mean-fraud?-1\">What does it mean fraud?</a></span></li><li><span><a href=\"#Important-libraries\" data-toc-modified-id=\"Important-libraries-2\">Important libraries</a></span></li><li><span><a href=\"#DataSet-description\" data-toc-modified-id=\"DataSet-description-3\">DataSet description</a></span></li><li><span><a href=\"#Understanding-our-data\" data-toc-modified-id=\"Understanding-our-data-4\">Understanding our data</a></span></li><li><span><a href=\"#Correlation-analysis\" data-toc-modified-id=\"Correlation-analysis-5\">Correlation analysis</a></span></li><li><span><a href=\"#Fraud/-non-Fraud-ratio\" data-toc-modified-id=\"Fraud/-non-Fraud-ratio-6\">Fraud/ non-Fraud ratio</a></span></li><li><span><a href=\"#Traditional-way-of-catching-fraud\" data-toc-modified-id=\"Traditional-way-of-catching-fraud-7\">Traditional way of catching fraud</a></span></li><li><span><a href=\"#Machine-Learning-models\" data-toc-modified-id=\"Machine-Learning-models-8\">Machine Learning models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-/-Test-sets\" data-toc-modified-id=\"Train-/-Test-sets-8.1\">Train / Test sets</a></span></li></ul></li><li><span><a href=\"#hybrid-base-rule-and-machine-learning-model\" data-toc-modified-id=\"hybrid-base-rule-and-machine-learning-model-9\">hybrid base-rule and machine learning model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-9.1\">Logistic Regression</a></span></li></ul></li><li><span><a href=\"#KNN\" data-toc-modified-id=\"KNN-10\">KNN</a></span></li><li><span><a href=\"#Decision-Trees\" data-toc-modified-id=\"Decision-Trees-11\">Decision Trees</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-12\">Random Forest</a></span></li><li><span><a href=\"#Adaboots\" data-toc-modified-id=\"Adaboots-13\">Adaboots</a></span></li><li><span><a href=\"#Gradient-Boosting\" data-toc-modified-id=\"Gradient-Boosting-14\">Gradient Boosting</a></span><ul class=\"toc-item\"><li><span><a href=\"#Histogram-based-Gradient-Boosting-Classification-Tree\" data-toc-modified-id=\"Histogram-based-Gradient-Boosting-Classification-Tree-14.1\">Histogram-based Gradient Boosting Classification Tree</a></span></li></ul></li><li><span><a href=\"#Model-Comparison\" data-toc-modified-id=\"Model-Comparison-15\">Model Comparison</a></span></li><li><span><a href=\"#Logistic-Regression-with-hyperparameter-tunning\" data-toc-modified-id=\"Logistic-Regression-with-hyperparameter-tunning-16\">Logistic Regression with hyperparameter tunning</a></span></li><li><span><a href=\"#Synthetic-Minority-Oversampling-Technique-(SMOTE)\" data-toc-modified-id=\"Synthetic-Minority-Oversampling-Technique-(SMOTE)-17\">Synthetic Minority Oversampling Technique (SMOTE)</a></span></li><li><span><a href=\"#Logistic-Regression-combined-with-SMOTE\" data-toc-modified-id=\"Logistic-Regression-combined-with-SMOTE-18\">Logistic Regression combined with SMOTE</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ea0a0",
   "metadata": {},
   "source": [
    "## Welcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e543c313",
   "metadata": {},
   "source": [
    "## What does it mean fraud?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c772480d",
   "metadata": {},
   "source": [
    "## Important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aabe5d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merche\\anaconda3\\envs\\Da_Env1\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#ploting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#hyperparameters tuning\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#model performance evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "\n",
    "#others\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import metrics\n",
    "from typing import Dict, Tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9cf5c",
   "metadata": {},
   "source": [
    "## DataSet description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241cac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9072aef5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv(\"Data/creditcard/creditcard.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7df1ab3",
   "metadata": {},
   "source": [
    "## Understanding our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c73f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de84672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do we have any missing value?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51c918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the dataset description the features from \"V1\" to \"V28\" are the result of PCA(Principal Components Analysis). \n",
    "#We know that features must be scaled before using this technique. \n",
    "#However the features \"Time\" and \"Amount\" are not scaled we should scaled them before continuing with our analysis. \n",
    "\n",
    "df['Amount_scaled'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "df['Time_scaled'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1, 1))\n",
    "\n",
    "#Now we have to drop from our dataset the features \"Time\" and \"Amount\":\n",
    "df=df.drop(columns=['Amount', 'Time'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d838b375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount_scaled</th>\n",
       "      <th>Time_scaled</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.996541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount_scaled  Time_scaled  Class  \n",
       "0 -0.189115  0.133558 -0.021053       0.244964    -1.996583      0  \n",
       "1  0.125895 -0.008983  0.014724      -0.342475    -1.996583      0  \n",
       "2 -0.139097 -0.055353 -0.059752       1.160686    -1.996562      0  \n",
       "3 -0.221929  0.062723  0.061458       0.140534    -1.996562      0  \n",
       "4  0.502292  0.219422  0.215153      -0.073403    -1.996541      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns) \n",
    "df = df[['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount_scaled','Time_scaled','Class']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab023a0",
   "metadata": {},
   "source": [
    "## Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1bb855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Correlation between the features and the dependent variable \"Class\":\n",
    "\n",
    "df[df.columns[0:]].corr()['Class'][:].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix:\n",
    "\n",
    "corr = df.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(30, 25))\n",
    "    ax = sns.heatmap(corr, mask=mask,cmap='coolwarm', vmin=-1,vmax=1,annot=True, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d4044",
   "metadata": {},
   "source": [
    "## Fraud/ non-Fraud ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f135a",
   "metadata": {},
   "source": [
    " the feature \"Class\" is our target variable. This variable has two possible values: \n",
    " 1 for fraudulent transactions and 0 for no fraudulent transactions. \n",
    "A very commun problem in classification datasets is classs imbalance. This means that the dataset contains an imbalance number of fraudulents and no-fraudulents transactions. ML algorithms works better when the different classes are equally represented  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Class'].value_counts()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5474c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio of fraudulent transactions\n",
    "y/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eff27d",
   "metadata": {},
   "source": [
    "We can see that fraudulent transactions represent only 0.1727% of our datasets meanwhile non-fraudulent transactions respresent 99.8273%.\n",
    "it is confirmed we have class imbalance in our dataset. \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f768a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualizations can be very a powerful tool to detect class imbalance:\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "sns.countplot('Class', data=df, palette=\"Set2\")\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcb9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also use a scatter plot to see our class imbalance. \n",
    "#First, we need to convert our dataframe in 2 variables:\n",
    "\n",
    "X=df.iloc[:,0:30].values\n",
    "y=df.Class.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c144b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X: np.ndarray, y: np.ndarray):\n",
    "    \n",
    " \n",
    "    sns.set_palette(\"Set2\")\n",
    "    \n",
    "    sns.scatterplot(X[y == 0, 0], X[y == 0, 1], label=\"Class #0\", alpha=0.5, linewidth=0.15)\n",
    "    sns.scatterplot(X[y == 1, 0], X[y == 1, 1], label=\"Class #1\", alpha=0.5, linewidth=0.15)\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4657b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea35db0",
   "metadata": {},
   "source": [
    "The plot helps us to see the data imbalance problem very clear. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03339d76",
   "metadata": {},
   "source": [
    "## Traditional way of catching fraud\n",
    "First you'll define threshold values using common statistics, to split fraud and non-fraud. Then, use those thresholds on your features to detect fraud. This is common practice within fraud analytics teams.\n",
    "\n",
    "Statistical thresholds are often determined by looking at the mean values of observations. Let's start this exercise by checking whether feature means differ between fraud and non-fraud cases. Then, you'll use that information to create common sense thresholds. Finally, you'll check how well this performs in fraud detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6494d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean=df.groupby('Class').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b28571",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ec3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a rule for stating which cases are flagged as fraud\n",
    "df['predicted_fraud'] = np.where(np.logical_and(df['V1'] < -3, df['V7'] < -5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38bbda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a crosstab of flagged fraud cases versus the actual fraud cases\n",
    "print(pd.crosstab(df.Class, df.predicted_fraud, rownames=['Fraud'], colnames=['Predicted_Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf14e2",
   "metadata": {},
   "source": [
    "With this first approach we have detected 157 of 492 fraudulent cases, and we got 824 false positives. Now we will see how we can improve these numbers with ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dcfc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do not need the feature \"flag as fraud\" for this analysis, so I will delete it\n",
    "df=df.drop(columns=['predicted_fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f049b205",
   "metadata": {},
   "source": [
    "## Machine Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f125d67b",
   "metadata": {},
   "source": [
    "### Train / Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc5c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XY split:\n",
    "\n",
    "X=df.drop('Class', axis=1)\n",
    "y=df.Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b267b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test set:\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.30, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d42e4fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression model recall score:0.6\n",
      "Decision Tree model recall score:0.75\n",
      "Random Forest Classifier model recall score:0.78\n",
      "Adaboost Classifier model recall score:0.65\n",
      "Light Gradient Boosting model recall score:0.56\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logisitic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"Adaboost Classifier\" :AdaBoostClassifier(),\n",
    "    \"Light Gradient Boosting\" :LGBMClassifier()\n",
    "    \n",
    "      \n",
    "}\n",
    "\n",
    "\n",
    "# Cross validation score for different classifiers using \"recall\" as scoring:\n",
    "\n",
    "for key, model in models.items():\n",
    "    model.fit(X_train,y_train)\n",
    "    score = cross_val_score(model, X, y, scoring='recall',cv=5)\n",
    "    print(f'{key} model recall score:{round(score.mean(), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03d94e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=10. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_samples_leaf=10 will be ignored. Current value: min_data_in_leaf=20\n"
     ]
    }
   ],
   "source": [
    "lgb_hyperparameters = {\"n_estimators\":[1,20,40,60,80,100],\n",
    "                      \"max_depth\":[2,3,4,5,6,8],\n",
    "                      \"learning_rate\":[0.01,0.1,0.2,0.5],\n",
    "                      \"min_samples_leaf\":[10,20,30],\n",
    "                     \"subsample\" : [0.1,0.2,0.5,0.9],\n",
    "                      \"num_leaves\":[20,30,40],\n",
    "                \n",
    "                      \"min_data_in_leaf\":[10,20,30]}\n",
    "\n",
    "\n",
    "search = GridSearchCV(LGBMClassifier(), lgb_hyperparameters, scoring='recall', n_jobs=-1, cv=5)\n",
    "result_lgb=search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11ce5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Recall Score: 0.8719522591645352\n",
      "Best Hyperparameters: {'learning_rate': 0.5, 'max_depth': 5, 'min_data_in_leaf': 20, 'min_samples_leaf': 10, 'n_estimators': 1, 'num_leaves': 20, 'subsample': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best Recall Score: %s' % result_lgb.best_score_)\n",
    "print('Best Hyperparameters: %s' % result_lgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeef4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbc = LGBMClassifier( subsample=0.1,n_estimators=1, max_depth=5, min_data_in_leaf=20, num_leaves= 20,\n",
    "                      learning_rate=0.5,min_samples_leaf=10)\n",
    "result_lgbc=lgbc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgbc=result_lgbc.predict(X_test)\n",
    "y_pred_probs_lgbc = result_lgbc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfab4d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for the test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.43      0.82      0.56       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.71      0.91      0.78     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,y_pred_lgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f14d0122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Confusion matrix for the test set before hyperparameter tunning\n",
      "[[85133   162]\n",
      " [   26   122]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Gradient Boosting Confusion matrix for the test set before hyperparameter tunning\")\n",
    "print(confusion_matrix(y_test, y_pred_lgbc))\n",
    "conf_mat = confusion_matrix(y_test,y_pred_lgbc)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_var = []\n",
    "for i in result_lgbc.feature_importances_:\n",
    "    imp_var.append(i)\n",
    "print('Top var =', imp_var.index(np.sort(lgbc.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', imp_var.index(np.sort(lgbc.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', imp_var.index(np.sort(lgbc.feature_importances_)[-3])+1)\n",
    "print('4rd Top var =', imp_var.index(np.sort(lgbc.feature_importances_)[-4])+1)\n",
    "print('5rd Top var =', imp_var.index(np.sort(lgbc.feature_importances_)[-5])+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3662a85",
   "metadata": {},
   "source": [
    "## hybrid base-rule and machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461168a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Class', axis=1)\n",
    "y=df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ebc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y,test_y=train_test_split(x,y,test_size=0.30, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class RuleAugmentedEstimator(BaseEstimator):\n",
    "    \"\"\"Augments sklearn estimators with rule-based logic.\n",
    "    This class is a wrapper class for sklearn estimators with the additional\n",
    "    possibility of adding rule-based logic to the underlying estimator.\n",
    "    The provided rules are hard-coded and take precedence over the underlying\n",
    "    estimator's predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_model: BaseEstimator, rules: Dict, **base_params):\n",
    "        \"\"\"Initializes the RuleAugmentedEstimator instance.\n",
    "        Initializes the rule-augmented estimator by supplying the underlying\n",
    "        sklearn estimator as well as the hard-coded rules.\n",
    "        Args:\n",
    "            base_model: The underlying sklearn estimator.\n",
    "              Must implement a fit and predict method.\n",
    "            rules: The hard-coded rules in the format of a dictionary,\n",
    "              with keys being the pandas dataframe column name, and the values\n",
    "              being a tuple in the following form:\n",
    "              \n",
    "              (comparison operator, value, return value)\n",
    "              Acceptable comparison operators are:\n",
    "              \"=\", \"<\", \">\", \"<=\", \">=\"\n",
    "              Example:\n",
    "              \n",
    "              {\"House Type\": [\n",
    "                  (\"=\", \"Penthouse\", 1.0),\n",
    "                  (\"=\", \"Shack\", 0.0)\n",
    "               ],\n",
    "               \"House Price\": [\n",
    "                   (\"<\", 1000.0, 0.0),\n",
    "                   (\">=\", 500000.0, 1.0)\n",
    "              ]}\n",
    "            **base_params: Optional keyword arguments which will be passed on\n",
    "            to the ``base_model``.\n",
    "        Examples:\n",
    "            The below example illustrates how an instance of the \n",
    "            RuleAugmentedEstimator class can be initialized with a trained \n",
    "            sklearn GradientBoostingRegressor instance.\n",
    "            >>> gbr = GradientBoostingRegressor()\n",
    "            >>> rules = {\"House Type\": [\n",
    "                            (\"=\", \"Penthouse\", 1.0),\n",
    "                            (\"=\", \"Shack\", 0.0)\n",
    "                         ],\n",
    "                         \"House Price\": [\n",
    "                            (\"<\", 1000.0, 0.0),\n",
    "                            (\">=\", 500000.0, 1.0)\n",
    "                        ]}\n",
    "            >>> ra_estimator = RuleAugmentedEstimator(gbr, rules)\n",
    "        \"\"\"\n",
    "\n",
    "        self.rules = rules\n",
    "        self.base_model = base_model\n",
    "        self.base_model.set_params(**base_params)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Rule Augmented Estimator:\\n\\n\\t Base Model: {}\\n\\t Rules: {}\".format(self.base_model, self.rules)\n",
    "\n",
    "    def __str__(self):\n",
    "         return self.__str__\n",
    "   \n",
    "    def _get_base_model_data(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"Filters the trainig data for data points not affected by the rules.\"\"\"\n",
    "        \n",
    "        train_x = X\n",
    "\n",
    "        for category, rules in self.rules.items():\n",
    "\n",
    "            if category not in train_x.columns.values: continue\n",
    "\n",
    "            for rule in rules:\n",
    "\n",
    "                if rule[0] == \"=\":\n",
    "                    train_x = train_x.loc[train_x[category] != rule[1]]\n",
    "\n",
    "                elif rule[0] == \"<\":\n",
    "                    train_x = train_x.loc[train_x[category] >= rule[1]]\n",
    "\n",
    "                elif rule[0] == \">\":\n",
    "                    train_x = train_x.loc[train_x[category] <= rule[1]]\n",
    "\n",
    "                elif rule[0] == \"<=\":\n",
    "                    train_x = train_x.loc[train_x[category] > rule[1]]\n",
    "\n",
    "                elif rule[0] == \">=\":\n",
    "                    train_x = train_x.loc[train_x[category] < rule[1]]\n",
    "\n",
    "                else:\n",
    "                    print(\"Invalid rule detected: {}\".format(rule))\n",
    "                \n",
    "        indices = train_x.index.values\n",
    "        train_y = y.iloc[indices]\n",
    "        \n",
    "        train_x = train_x.reset_index(drop=True)\n",
    "        train_y = train_y.reset_index(drop=True)\n",
    "        \n",
    "        return train_x, train_y   \n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, **kwargs):\n",
    "        \"\"\"Fits the estimator to the data.\n",
    "        \n",
    "        Fits the estimator to the data, only training the underlying estimator\n",
    "        on data which isn't affected by the hard-coded rules.\n",
    "        \n",
    "        Args:\n",
    "            X: The training feature data.\n",
    "            y: The training label data.\n",
    "            **kwargs: Optional keyword arguments passed to the underlying\n",
    "            estimator's fit function.\n",
    "            \n",
    "    \"\"\"\n",
    "        train_x, train_y = self._get_base_model_data(X, y)\n",
    "        self.base_model.fit(train_x, train_y, **kwargs)\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Gets predictions for the provided feature data.\n",
    "        \n",
    "        The predicitons are evaluated using the provided rules wherever possible\n",
    "        otherwise the underlying estimator is used.\n",
    "        \n",
    "        Args:\n",
    "            X: The feature data to evaluate predictions for.\n",
    "        \n",
    "        Returns:\n",
    "            np.array: Evaluated predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        p_X = X.copy()\n",
    "        p_X['prediction'] = np.nan\n",
    "\n",
    "        for category, rules in self.rules.items():\n",
    "\n",
    "            if category not in p_X.columns.values: continue\n",
    "\n",
    "            for rule in rules:\n",
    "\n",
    "                if rule[0] == \"=\":\n",
    "                    p_X.loc[p_X[category] == rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "                elif rule[0] == \"<\":\n",
    "                    p_X.loc[p_X[category] < rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "                elif rule[0] == \">\":\n",
    "                    p_X.loc[p_X[category] > rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "                elif rule[0] == \"<=\":\n",
    "                    p_X.loc[p_X[category] <= rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "                elif rule[0] == \">=\":\n",
    "                    p_X.loc[p_X[category] >= rule[1], 'prediction'] = rule[2]\n",
    "\n",
    "                else:\n",
    "                    print(\"Invalid rule detected: {}\".format(rule))\n",
    "\n",
    "        if len(p_X.loc[p_X['prediction'].isna()].index != 0):\n",
    "\n",
    "            base_X = p_X.loc[p_X['prediction'].isna()].copy()\n",
    "            base_X.drop('prediction', axis=1, inplace=True)\n",
    "            p_X.loc[p_X['prediction'].isna(), 'prediction'] = self.base_model.predict(base_X)\n",
    "\n",
    "        return p_X['prediction'].values\n",
    "    \n",
    "    def get_params(self, deep: bool = True) -> Dict:\n",
    "        \"\"\"Return the model's and base model's parameters.\n",
    "        Args:\n",
    "            deep: Whether to recursively return the base model's parameters.\n",
    "        Returns\n",
    "            Dict: The model's parameters.\n",
    "        \"\"\"\n",
    "        \n",
    "        params = {'base_model': self.base_model,\n",
    "                  'outcome_range': self.outcome_range,\n",
    "                  'rules': self.rules\n",
    "                 }\n",
    "    \n",
    "        params.update(self.base_model.get_params(deep=deep))\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        \"\"\"Sets parameters for the model and base model.\n",
    "        Args:\n",
    "            **params: Optional keyword arguments.\n",
    "        \"\"\"\n",
    "                  \n",
    "        parameters = params\n",
    "        param_keys = parameters.keys()\n",
    "        \n",
    "        if 'base_model' in param_keys:\n",
    "            value = parameters.pop('base_model')\n",
    "            self.base_model = value\n",
    "            \n",
    "        if 'rules' in param_keys:\n",
    "            value = parameters.pop('rules')\n",
    "            self.rules = value\n",
    "        \n",
    "        self.base_model.set_params(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355299f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assume GradientBoostingRegressor was trained on data\n",
    "\n",
    "rules = { \n",
    "          \"V17\": [\n",
    "            (\"<\", -2.5, 1.0),\n",
    "            (\">=\", -2.5, 0.0)]\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "logreg= LogisticRegression()\n",
    "dtc= DecisionTreeClassifier()\n",
    "rfc= RandomForestClassifier()\n",
    "ada=AdaBoostClassifier()\n",
    "lgb= LGBMClassifier()\n",
    "    \n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "# Cross validation score for different classifiers using \"recall\" as scoring:\n",
    "\n",
    "\n",
    "         \n",
    "ra_estimator = RuleAugmentedEstimator(lgb, rules)\n",
    "\n",
    "# Now, the RuleAugmentedEstimator can be used similarily to the underlying base estimator, assuming data X is defined\n",
    "\n",
    "predictions = ra_estimator.predict(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2887912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(test_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Boosting Confusion matrix for the test set before hyperparameter tunning\")\n",
    "print(confusion_matrix(test_y, predictions))\n",
    "conf_mat = confusion_matrix(test_y,predictions)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59213f69",
   "metadata": {},
   "outputs": [],
   "source": [
    " \"V17\": [\n",
    "            (\"<\", -2.5, 1.0),\n",
    "            (\">=\", -2.5, 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942eb16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "228c46b8",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26857488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define our model\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "\n",
    "#fit our the model with our training set\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Get predicting values\n",
    "y_predicted_logreg=logreg.predict(X_test)\n",
    "#predicted_y_train=model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c89628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print classification report for the test set\n",
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,y_predicted_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, y_predicted_logreg))\n",
    "conf_mat = confusion_matrix(y_test,y_predicted_logreg)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "#Calculate roc_auc_score\n",
    "print(\"roc_auc_score of logistic regression classifier: \",roc_auc_score(y_test, y_pred_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013761d5",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df885ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define the model with our best parameters and the resampling:\n",
    "knn=KNeighborsClassifier()\n",
    "\n",
    "\n",
    "##fit our pipeline with our training set\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Get predicting values\n",
    "y_predicted_knn=knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report for the test set\n",
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,y_predicted_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, y_predicted_knn))\n",
    "conf_mat = confusion_matrix(y_test,y_predicted_knn)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs_knn = knn.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "#Calculate roc_auc_score\n",
    "print(\"roc_auc_score of knn classifier: \",roc_auc_score(y_test, y_pred_probs_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f79c4",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use GridSearchCV in order to find the best parameters for our decision tree\n",
    "hyperparameters = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n",
    "              \"min_samples_leaf\": list(range(5,7,1))}\n",
    "\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(), hyperparameters, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "best_model = gridsearch.fit(X_train, y_train)\n",
    "print(best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e164f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define the model with our best parameters and the resampling:\n",
    "dtc= DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "##fit our pipeline with our training set\n",
    "dtc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Get predicting values\n",
    "y_predicted_dtc=dtc.predict(X_test)\n",
    "\n",
    "#predicted_y_train=model.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36daf05b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print classification report for the test set\n",
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,y_predicted_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba64ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, y_predicted_dtc))\n",
    "conf_mat = confusion_matrix(y_test,y_predicted_dtc)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcf4f8d",
   "metadata": {},
   "source": [
    "performance_model = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, predicted_y_train),\n",
    "                                         precision_score(y_train, predicted_y_train),\n",
    "                                         recall_score(y_train, predicted_y_train)],\n",
    "                               'Test': [accuracy_score(y_test, predicted_y_test),\n",
    "                                        precision_score(y_test, predicted_y_test),\n",
    "                                        recall_score(y_test, predicted_y_test)]})\n",
    "display(performance_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eeeec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs_dtc = dtc.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "#Calculate roc_auc_score\n",
    "print(\"roc_auc_score of decision tree classifier: \",roc_auc_score(y_test, y_pred_probs_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59647d95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tree Representation :\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (20,20))\n",
    "\n",
    "\n",
    "plot_tree(dtc,filled = True, rounded=True,feature_names=X.columns, class_names=['No Fraud', \"Fraud\"])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc23afa7",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb258fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use GridSearchCV in order to find the best parameters for our random forest\n",
    "\n",
    "\n",
    "hyperparameters = {'n_estimators': [1, 30],\n",
    "              'max_features': ['auto', 'log2'], \n",
    "              'max_depth': [4, 8, 10, 12],\n",
    "              'criterion': ['gini', 'entropy']}\n",
    "\n",
    "\n",
    "gridsearch = GridSearchCV(RandomForestClassifier(), hyperparameters, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "best_model = gridsearch.fit(X_train, y_train)\n",
    "print(best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model with our best parameters\n",
    "rfc= RandomForestClassifier()\n",
    "\n",
    "\n",
    "#fit our pipeline with our training set\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "# Get predicting values\n",
    "y_predicted_rfc=rfc.predict(X_test)\n",
    "\n",
    "#predicted_y_train=model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a015a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report for the test set\n",
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,y_predicted_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fa29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, y_predicted_rfc))\n",
    "conf_mat = confusion_matrix(y_test,y_predicted_rfc)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ccb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs_rfc = rfc.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "#Calculate roc_auc_score\n",
    "print(\"roc_auc_score of random forest classifier: \",roc_auc_score(y_test, y_pred_probs_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e521c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rfc.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(7,7))\n",
    "\n",
    "importances_sorted.plot(kind='barh', color='#BCD8C1')\n",
    "plt.title('Features Importances')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6631c720",
   "metadata": {},
   "source": [
    "## Adaboots\n",
    "An AdaBoost [1] classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "# Fit ada to the training set\n",
    "ada.fit(X_train,y_train)\n",
    "\n",
    "# Get predicting values\n",
    "predicted=ada.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d63986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report for the test set\n",
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21872ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_test,predicted)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs_ada = ada.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "#Calculate roc_auc_score\n",
    "print(\"roc_auc_score of Adaboots classifier: \",roc_auc_score(y_test,y_pred_probs_ada ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=ada.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(7,7))\n",
    "\n",
    "importances_sorted.plot(kind='barh', color='#BCD8C1')\n",
    "plt.title('Features Importances')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840d54d",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate ada\n",
    "gbc= GradientBoostingClassifier()\n",
    "\n",
    "# Fit ada to the training set\n",
    "gbc.fit(X_train,y_train)\n",
    "\n",
    "# Get predicting values\n",
    "y_predicted_gbc=gbc.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba_gbc = gbc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report for the test set\n",
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,y_predicted_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a71ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, y_predicted_gbc))\n",
    "conf_mat = confusion_matrix(y_test,y_predicted_gbc)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs_gbc = gbc.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "#Calculate roc_auc_score\n",
    "print(\"roc_auc_score of Gradient Booster classifier: \",roc_auc_score(y_test,y_pred_probs_gbc ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7608175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=gbc.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(7,7))\n",
    "\n",
    "importances_sorted.plot(kind='barh', color='#BCD8C1')\n",
    "plt.title('Features Importances')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d9612",
   "metadata": {},
   "source": [
    "### Histogram-based Gradient Boosting Classification Tree\n",
    "\n",
    "This estimator is much faster than GradientBoostingClassifier for big datasets (n_samples >= 10 000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d84d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate histGradientBoostingClassifier\n",
    "hgbc= HistGradientBoostingClassifier()\n",
    "\n",
    "# Fit ada to the training set\n",
    "hgbc.fit(X_train,y_train)\n",
    "\n",
    "# Get predicting values\n",
    "y_predicted_hgbc=hgbc.predict(X_test)\n",
    "\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba_hgbc = hgbc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfe527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report for the test set\n",
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,y_predicted_hgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ba497",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, y_predicted_hgbc))\n",
    "conf_mat = confusion_matrix(y_test,y_predicted_hgbc)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7853050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs_hgbc = hgbc.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "#Calculate roc_auc_score\n",
    "print(\"roc_auc_score of Gradient Booster classifier: \",roc_auc_score(y_test,y_pred_probs_hgbc ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d8127e",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b35ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_probs)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred_probs), 4)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#knn\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_probs_knn)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred_probs_knn), 4)\n",
    "plt.plot(fpr,tpr,label=\"Knn, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "#decision tree\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_probs_dtc)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred_probs_dtc), 4)\n",
    "plt.plot(fpr,tpr,label=\"Descision Tree, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "#random forest\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_probs_rfc)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred_probs_rfc), 4)\n",
    "plt.plot(fpr,tpr,label=\"Random forest, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "#adaboost\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_probs_ada )\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred_probs_ada), 4)\n",
    "plt.plot(fpr,tpr,label=\"Adaboost, AUC=\"+str(auc))\n",
    "\n",
    "#gradient Boosting\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_probs_gbc )\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred_probs_gbc), 4)\n",
    "plt.plot(fpr,tpr,label=\"Gradient boosting, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "#histgradientbooting\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_probs_hgbc )\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred_probs_hgbc), 4)\n",
    "plt.plot(fpr,tpr,label=\"Histogram-Based Gradient boosting, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d194bc3",
   "metadata": {},
   "source": [
    "## Logistic Regression with hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ab0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use GridSearch in order to find the best parameters for our logistic Regression model:\n",
    "\n",
    "#First we define the evaluation metrics:\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#We create a dictionary for our hyperparameters:\n",
    "hyperparameters = {\"penalty\": ['none', 'l1', 'l2', 'elasticnet'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\"solver\" : ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "\n",
    "gridsearch = GridSearchCV(LogisticRegression(), hyperparameters, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "best_model = gridsearch.fit(X_train, y_train)\n",
    "print(best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d92205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our model\n",
    "logreg=LogisticRegression(C=0.001,penalty=\"none\",solver='newton-cg')\n",
    "\n",
    "#fit our the model with our training set\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Get predicting values\n",
    "\n",
    "y_predicted_logreg=logreg.predict(X_test)\n",
    "#predicted_y_train=model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7dbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report for the test set\n",
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,y_predicted_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test, y_predicted_logreg))\n",
    "conf_mat = confusion_matrix(y_test,y_predicted_logreg)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d096b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "#Calculate roc_auc_score\n",
    "print(\"roc_auc_score of logistic regression classifier: \",roc_auc_score(y_test, y_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981cb1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228573d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61680e19",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "    Data analysis with imbalance data is bias. All our model are better predicting the class 0 \n",
    "    Possible overfitting\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23067a",
   "metadata": {},
   "source": [
    "##  Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37c3f7",
   "metadata": {},
   "source": [
    "In order to treat the data imbanlance we can use oversampling and undersampling techniques. SMOTE is an oversampling technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=df.iloc[:,0:30].values\n",
    "y=df.Class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X shape: {X.shape}\\ny shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7784b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the resampling method\n",
    "method = SMOTE(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resampled feature set\n",
    "X_sm, y_sm = method.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebccb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(pd.Series(y_sm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2585ab",
   "metadata": {},
   "source": [
    "# Plot the resampled data\n",
    "plot_data(X_sm, y_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7b9ba",
   "metadata": {},
   "source": [
    "def compare_plot(X: np.ndarray, y: np.ndarray, X_resampled: np.ndarray, y_resampled: np.ndarray, method: str):\n",
    "    sns.set_palette(\"Set2\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], label=\"Class #0\", alpha=0.5, linewidth=0.15)\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], label=\"Class #1\", alpha=0.5, linewidth=0.15)\n",
    "    plt.title('Original Set')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(X_sm[y_sm == 0, 0], X_sm[y_sm == 0, 1], label=\"Class #0\", alpha=0.5, linewidth=0.15)\n",
    "    plt.scatter(X_sm[y_sm == 1, 0], X_sm[y_sm == 1, 1], label=\"Class #1\", alpha=0.5, linewidth=0.15)\n",
    "    plt.title(method)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot(X, y, X_sm, y_sm, method='SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be05e504",
   "metadata": {},
   "source": [
    "## Logistic Regression combined with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Define the resampling method and the model the model:\n",
    "resampling = SMOTE()\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define the pipeline, tell it to combine SMOTE with the Logistic Regression model\n",
    "pipeline = Pipeline([('SMOTE', resampling), ('Logistic Regression', model)])\n",
    "\n",
    "# XY split:\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.30, random_state=0)\n",
    "\n",
    "\n",
    "#fit the pipeline into the training set:\n",
    "pipeline.fit(X_train, y_train) \n",
    "\n",
    "#Get predictions:\n",
    "predicted_logreg_sm = pipeline.predict(X_test)\n",
    "\n",
    "#Calculate the accuracy\n",
    "print(\"accuracy for logistic regression combined with SMOTE: \",accuracy_score(y_test, predicted_logreg_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report for the test set\n",
    "print(\"Classification report for the test set\")\n",
    "print(classification_report(y_test,predicted_logreg_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff5636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix for the test set\")\n",
    "print(confusion_matrix(y_test,predicted_logreg_sm))\n",
    "conf_mat = confusion_matrix(y_test,predicted_logreg_sm)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='icefire', fmt='d', cbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b158f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the accuracy\n",
    "print(\"accuracy for logistic regression combined with SMOTE: \",accuracy_score(y_test, predicted_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba85188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Plot tpr against fpr\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for fraudulent transactions')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Calculate roc_auc_score\n",
    "print(\"roc_auc_score of logistic regression classifier: \",roc_auc_score(y_test, y_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab25f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Logistic Regression\": logreg, \"Decision Trees\": dtc, \"Random Forest\": rfc}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = [ logreg,dtc,rfc]\n",
    "model_names = ['Logistic Regresion','Decision Tree','Random Forest']\n",
    "scores = {}\n",
    "i=0\n",
    "for model in model_pipeline:\n",
    "    mean_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "    scores[model_names[i]] = mean_score\n",
    "    i = i+1\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "757px",
    "left": "1501px",
    "top": "123px",
    "width": "383.962px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
